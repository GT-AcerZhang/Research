{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "百度发布首个大规模隐变量对话模型PLATO - 飞桨PaddlePaddle的文章 - 知乎\n",
    "https://zhuanlan.zhihu.com/p/131019469\n",
    "\n",
    "PLATO: Pre-trained Dialogue  GenerationModel with Discrete Latent Variable\n",
    "\n",
    "PLATO：具有离散潜变量的预训练对话生成模型\n",
    "\n",
    "PLATO可以灵活支持多种对话，包括闲聊、知识聊天、对话问答等等。\n",
    "文章最终公布的在三个公开对话数据集上的测试，PLATO都取得了新的最优效果。\n",
    "\n",
    "为了验证预训练模型的效果，论文在3个公开对话数据集上进行了测试：Persona-Chat、Daily Dialog以及DSTC7-AVSD。\n",
    "\n",
    "\n",
    "- Persona-Chat是典型的知识聊天任务：两个人讲述自己信息（Persona Profiles），并在对话中尽量了解对方；\n",
    "- Daily Dialog偏向日常闲聊类型；\n",
    "- DSTC7-AVSD是对话式问答，根据视频场景信息，两人进行多轮问答，讨论视频中物体和事件。\n",
    "\n",
    "![](https://pic4.zhimg.com/80/v2-a18f47a577fe46dc0f945b14f751aeab_1440w.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: env/bin/active: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!source env/bin/active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting paddlepaddle==1.6.0 (from -r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/be/f7/1f822860a6689960ea66f30ee9a74703253f665768ed3a833ec9dfdbd2dd/paddlepaddle-1.6.0-cp37-cp37m-macosx_10_6_intel.whl (40.1MB)\n",
      "\u001b[K     |████████████████████████████████| 40.1MB 292kB/s eta 0:00:011     |█████████████████▏              | 21.6MB 42.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/huihui/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.16.4)\n",
      "Requirement already satisfied: nltk in /Users/huihui/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.2.5)\n",
      "Requirement already satisfied: tqdm in /Users/huihui/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (4.43.0)\n",
      "Requirement already satisfied: regex in /Users/huihui/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (2019.12.9)\n",
      "Requirement already satisfied: Pillow in /Users/huihui/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.6.0->-r requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /Users/huihui/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.6.0->-r requirements.txt (line 1)) (2.22.0)\n",
      "Requirement already satisfied: six in /Users/huihui/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.6.0->-r requirements.txt (line 1)) (1.12.0)\n",
      "Requirement already satisfied: decorator in /Users/huihui/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.6.0->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: scipy; python_version >= \"3.5\" in /Users/huihui/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.6.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Collecting funcsigs (from paddlepaddle==1.6.0->-r requirements.txt (line 1))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /Users/huihui/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.6.0->-r requirements.txt (line 1)) (5.1.1)\n",
      "Collecting objgraph (from paddlepaddle==1.6.0->-r requirements.txt (line 1))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/7d/21/b8ea10bea21a3ecb603ab0a8a59e49282d83eadba16e47464193b0b70dce/objgraph-3.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /Users/huihui/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.6.0->-r requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: graphviz in /Users/huihui/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.6.0->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /Users/huihui/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.6.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Collecting prettytable (from paddlepaddle==1.6.0->-r requirements.txt (line 1))\n",
      "Collecting rarfile (from paddlepaddle==1.6.0->-r requirements.txt (line 1))\n",
      "Collecting opencv-python (from paddlepaddle==1.6.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7c/0b/df5987ee6671eb7645d990b70832780daf0ece89469af0a792d8dcbcfe62/opencv_python-4.2.0.34-cp37-cp37m-macosx_10_9_x86_64.whl (49.1MB)\n",
      "\u001b[K     |████████████████████████████████| 49.1MB 205kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/huihui/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.6.0->-r requirements.txt (line 1)) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/huihui/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.6.0->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/huihui/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.6.0->-r requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/huihui/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.6.0->-r requirements.txt (line 1)) (1.24.2)\n",
      "Requirement already satisfied: setuptools in /Users/huihui/anaconda3/lib/python3.7/site-packages (from protobuf>=3.1.0->paddlepaddle==1.6.0->-r requirements.txt (line 1)) (42.0.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/huihui/anaconda3/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle==1.6.0->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/huihui/anaconda3/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle==1.6.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/huihui/anaconda3/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle==1.6.0->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/huihui/anaconda3/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle==1.6.0->-r requirements.txt (line 1)) (2.8.0)\n",
      "Installing collected packages: funcsigs, objgraph, prettytable, rarfile, opencv-python, paddlepaddle\n",
      "Successfully installed funcsigs-1.0.2 objgraph-3.4.1 opencv-python-4.2.0.34 paddlepaddle-1.6.0 prettytable-0.7.2 rarfile-3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ SAVE_DIR=outputs/DailyDialog.baseline.infer\n",
      "+ VOCAB_PATH=model/Bert/vocab.txt\n",
      "+ DATA_DIR=data/DailyDialog\n",
      "+ INIT_CHECKPOINT=outputs/DailyDialog.baseline/best.model\n",
      "+ DATA_TYPE=multi\n",
      "+ export CUDA_VISIBLE_DEVICES=0\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ export FLAGS_fraction_of_gpu_memory_to_use=0.1\n",
      "+ FLAGS_fraction_of_gpu_memory_to_use=0.1\n",
      "+ export FLAGS_eager_delete_scope=True\n",
      "+ FLAGS_eager_delete_scope=True\n",
      "+ export FLAGS_eager_delete_tensor_gb=0.0\n",
      "+ FLAGS_eager_delete_tensor_gb=0.0\n",
      "+ python -u ./preprocess.py --vocab_path model/Bert/vocab.txt --data_dir data/DailyDialog --data_type multi\n",
      "Reading examples from 'data/DailyDialog/dial.valid' ...\n",
      "7069it [00:14, 493.03it/s]\n",
      "Built 7069 VALID examples (0 filtered)\n",
      "Saving examples to 'data/DailyDialog/dial.valid.Bert.jsonl' ...\n",
      "Saved 7069 examples (elapsed 0.22s)\n",
      "Reading examples from 'data/DailyDialog/dial.test' ...\n",
      "6740it [00:11, 580.50it/s]\n",
      "Built 6740 TEST examples (0 filtered)\n",
      "Saving examples to 'data/DailyDialog/dial.test.Bert.jsonl' ...\n",
      "Saved 6740 examples (elapsed 0.18s)\n",
      "Reading examples from 'data/DailyDialog/dial.train' ...\n",
      "76052it [02:18, 550.21it/s]\n",
      "Built 76052 TRAIN examples (0 filtered)\n",
      "Saving examples to 'data/DailyDialog/dial.train.Bert.jsonl' ...\n",
      "Saved 76052 examples (elapsed 1.81s)\n",
      "+ python -u ./run.py --do_infer true --vocab_path model/Bert/vocab.txt --data_dir data/DailyDialog --data_type multi --batch_size 48 --num_latent 0 --num_type_embeddings 2 --init_checkpoint outputs/DailyDialog.baseline/best.model --length_average true --save_dir outputs/DailyDialog.baseline.infer\n",
      "{\n",
      "  \"do_train\": false,\n",
      "  \"do_test\": false,\n",
      "  \"do_infer\": true,\n",
      "  \"num_infer_batches\": null,\n",
      "  \"hparams_file\": null,\n",
      "  \"BPETextField\": {\n",
      "    \"vocab_path\": \"model/Bert/vocab.txt\",\n",
      "    \"filtered\": false,\n",
      "    \"max_len\": 256,\n",
      "    \"min_utt_len\": 1,\n",
      "    \"max_utt_len\": 50,\n",
      "    \"min_ctx_turn\": 1,\n",
      "    \"max_ctx_turn\": 16,\n",
      "    \"max_knowledge_num\": 16,\n",
      "    \"max_knowledge_len\": 16,\n",
      "    \"tokenizer_type\": \"Bert\"\n",
      "  },\n",
      "  \"Dataset\": {\n",
      "    \"data_dir\": \"data/DailyDialog\",\n",
      "    \"data_type\": \"multi\"\n",
      "  },\n",
      "  \"Trainer\": {\n",
      "    \"use_data_distributed\": false,\n",
      "    \"valid_metric_name\": \"-loss\",\n",
      "    \"num_epochs\": 10,\n",
      "    \"save_dir\": \"outputs/DailyDialog.baseline.infer\",\n",
      "    \"batch_size\": 48,\n",
      "    \"log_steps\": 100,\n",
      "    \"valid_steps\": 2000,\n",
      "    \"save_checkpoint\": true,\n",
      "    \"save_summary\": false,\n",
      "    \"shuffle\": true,\n",
      "    \"sort_pool_size\": 0\n",
      "  },\n",
      "  \"Model\": {\n",
      "    \"init_checkpoint\": \"outputs/DailyDialog.baseline/best.model\",\n",
      "    \"model\": \"UnifiedTransformer\",\n",
      "    \"num_token_embeddings\": -1,\n",
      "    \"num_pos_embeddings\": 512,\n",
      "    \"num_type_embeddings\": 2,\n",
      "    \"num_turn_embeddings\": 16,\n",
      "    \"num_latent\": 0,\n",
      "    \"tau\": 0.67,\n",
      "    \"with_bow\": true,\n",
      "    \"hidden_dim\": 768,\n",
      "    \"num_heads\": 12,\n",
      "    \"num_layers\": 12,\n",
      "    \"padding_idx\": 0,\n",
      "    \"dropout\": 0.1,\n",
      "    \"embed_dropout\": 0.0,\n",
      "    \"attn_dropout\": 0.1,\n",
      "    \"ff_dropout\": 0.1,\n",
      "    \"use_discriminator\": false,\n",
      "    \"dis_ratio\": 1.0,\n",
      "    \"weight_sharing\": true,\n",
      "    \"pos_trainable\": true,\n",
      "    \"two_layer_predictor\": false,\n",
      "    \"bidirectional_context\": true,\n",
      "    \"label_smooth\": 0.0,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"lr\": 5e-05,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"max_grad_norm\": null\n",
      "  },\n",
      "  \"Generator\": {\n",
      "    \"generator\": \"BeamSearch\",\n",
      "    \"min_gen_len\": 1,\n",
      "    \"max_gen_len\": 30,\n",
      "    \"beam_size\": 5,\n",
      "    \"length_average\": true,\n",
      "    \"length_penalty\": -1.0,\n",
      "    \"ignore_unk\": true\n",
      "  }\n",
      "}\n",
      "E0423 11:23:02.181319 226471360 pybind.cc:1149] Cannot use GPU because you have installed CPU version PaddlePaddle.\n",
      "If you want to use GPU, please try to install GPU version PaddlePaddle by: pip install paddlepaddle-gpu\n",
      "If you only have CPU, please change CUDAPlace(0) to be CPUPlace().\n"
     ]
    }
   ],
   "source": [
    "!sh scripts/DailyDialog/baseline_infer.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ SAVE_DIR=outputs/DailyDialog.baseline.infer\n",
      "+ VOCAB_PATH=model/Bert/vocab.txt\n",
      "+ DATA_DIR=data/DailyDialog\n",
      "+ INIT_CHECKPOINT=outputs/DailyDialog.baseline/best.model\n",
      "+ DATA_TYPE=multi\n",
      "+ export FLAGS_fraction_of_gpu_memory_to_use=0.1\n",
      "+ FLAGS_fraction_of_gpu_memory_to_use=0.1\n",
      "+ export FLAGS_eager_delete_scope=True\n",
      "+ FLAGS_eager_delete_scope=True\n",
      "+ export FLAGS_eager_delete_tensor_gb=0.0\n",
      "+ FLAGS_eager_delete_tensor_gb=0.0\n",
      "+ python -u ./preprocess.py --vocab_path model/Bert/vocab.txt --data_dir data/DailyDialog --data_type multi\n",
      "+ python -u ./run.py --do_infer true --vocab_path model/Bert/vocab.txt --data_dir data/DailyDialog --data_type multi --batch_size 48 --num_latent 0 --num_type_embeddings 2 --init_checkpoint outputs/DailyDialog.baseline/best.model --length_average true --save_dir outputs/DailyDialog.baseline.infer\n",
      "{\n",
      "  \"do_train\": false,\n",
      "  \"do_test\": false,\n",
      "  \"do_infer\": true,\n",
      "  \"num_infer_batches\": null,\n",
      "  \"hparams_file\": null,\n",
      "  \"BPETextField\": {\n",
      "    \"vocab_path\": \"model/Bert/vocab.txt\",\n",
      "    \"filtered\": false,\n",
      "    \"max_len\": 256,\n",
      "    \"min_utt_len\": 1,\n",
      "    \"max_utt_len\": 50,\n",
      "    \"min_ctx_turn\": 1,\n",
      "    \"max_ctx_turn\": 16,\n",
      "    \"max_knowledge_num\": 16,\n",
      "    \"max_knowledge_len\": 16,\n",
      "    \"tokenizer_type\": \"Bert\"\n",
      "  },\n",
      "  \"Dataset\": {\n",
      "    \"data_dir\": \"data/DailyDialog\",\n",
      "    \"data_type\": \"multi\"\n",
      "  },\n",
      "  \"Trainer\": {\n",
      "    \"use_data_distributed\": false,\n",
      "    \"valid_metric_name\": \"-loss\",\n",
      "    \"num_epochs\": 10,\n",
      "    \"save_dir\": \"outputs/DailyDialog.baseline.infer\",\n",
      "    \"batch_size\": 48,\n",
      "    \"log_steps\": 100,\n",
      "    \"valid_steps\": 2000,\n",
      "    \"save_checkpoint\": true,\n",
      "    \"save_summary\": false,\n",
      "    \"shuffle\": true,\n",
      "    \"sort_pool_size\": 0\n",
      "  },\n",
      "  \"Model\": {\n",
      "    \"init_checkpoint\": \"outputs/DailyDialog.baseline/best.model\",\n",
      "    \"model\": \"UnifiedTransformer\",\n",
      "    \"num_token_embeddings\": -1,\n",
      "    \"num_pos_embeddings\": 512,\n",
      "    \"num_type_embeddings\": 2,\n",
      "    \"num_turn_embeddings\": 16,\n",
      "    \"num_latent\": 0,\n",
      "    \"tau\": 0.67,\n",
      "    \"with_bow\": true,\n",
      "    \"hidden_dim\": 768,\n",
      "    \"num_heads\": 12,\n",
      "    \"num_layers\": 12,\n",
      "    \"padding_idx\": 0,\n",
      "    \"dropout\": 0.1,\n",
      "    \"embed_dropout\": 0.0,\n",
      "    \"attn_dropout\": 0.1,\n",
      "    \"ff_dropout\": 0.1,\n",
      "    \"use_discriminator\": false,\n",
      "    \"dis_ratio\": 1.0,\n",
      "    \"weight_sharing\": true,\n",
      "    \"pos_trainable\": true,\n",
      "    \"two_layer_predictor\": false,\n",
      "    \"bidirectional_context\": true,\n",
      "    \"label_smooth\": 0.0,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"lr\": 5e-05,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"max_grad_norm\": null\n",
      "  },\n",
      "  \"Generator\": {\n",
      "    \"generator\": \"BeamSearch\",\n",
      "    \"min_gen_len\": 1,\n",
      "    \"max_gen_len\": 30,\n",
      "    \"beam_size\": 5,\n",
      "    \"length_average\": true,\n",
      "    \"length_penalty\": -1.0,\n",
      "    \"ignore_unk\": true\n",
      "  }\n",
      "}\n",
      "E0423 11:26:37.943078 284114368 pybind.cc:1149] Cannot use GPU because you have installed CPU version PaddlePaddle.\n",
      "If you want to use GPU, please try to install GPU version PaddlePaddle by: pip install paddlepaddle-gpu\n",
      "If you only have CPU, please change CUDAPlace(0) to be CPUPlace().\n"
     ]
    }
   ],
   "source": [
    "!sh scripts/DailyDialog/baseline_infer.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看这样子是必须要有GPU了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOCAB_PATH=model/Bert/vocab.txt\n",
    "DATA_DIR=data/DSTC7_AVSD\n",
    "DATA_TYPE=multi_knowledge\n",
    "python -u \\\n",
    "    ./preprocess.py \\\n",
    "    --vocab_path $VOCAB_PATH \\\n",
    "    --data_dir $DATA_DIR \\\n",
    "    --data_type $DATA_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE_DIR=outputs/PersonaChat\n",
    "VOCAB_PATH=model/Bert/vocab.txt\n",
    "DATA_DIR=data/PersonaChat\n",
    "INIT_CHECKPOINT=model/PLATO\n",
    "DATA_TYPE=multi_knowledge\n",
    "\n",
    "python -u \\\n",
    "    ./preprocess.py \\\n",
    "    --vocab_path $VOCAB_PATH \\\n",
    "    --data_dir $DATA_DIR \\\n",
    "    --data_type $DATA_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"Good morning , sir . Is there a bank near here ? __eou__ There is one . 5 blocks away from here ? __eou__ Well , that's too far.Can you change some money for me ? __eou__ Surely , of course . What kind of currency have you got ?\tRIB .\"\n",
    "src, tgt = line.strip(\"\\n\").split(\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Good morning , sir . Is there a bank near here ? __eou__ There is one . 5 blocks away from here ? __eou__ Well , that's too far.Can you change some money for me ? __eou__ Surely , of course . What kind of currency have you got ?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RIB .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['good',\n",
       "  'morning',\n",
       "  ',',\n",
       "  'sir',\n",
       "  '.',\n",
       "  'is',\n",
       "  'there',\n",
       "  'a',\n",
       "  'bank',\n",
       "  'near',\n",
       "  'here',\n",
       "  '?'],\n",
       " ['there', 'is', 'one', '.', '5', 'blocks', 'away', 'from', 'here', '?'],\n",
       " ['well',\n",
       "  ',',\n",
       "  'that',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'too',\n",
       "  'far',\n",
       "  '.',\n",
       "  'can',\n",
       "  'you',\n",
       "  'change',\n",
       "  'some',\n",
       "  'money',\n",
       "  'for',\n",
       "  'me',\n",
       "  '?'],\n",
       " ['surely',\n",
       "  ',',\n",
       "  'of',\n",
       "  'course',\n",
       "  '.',\n",
       "  'what',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'currency',\n",
       "  'have',\n",
       "  'you',\n",
       "  'got',\n",
       "  '?']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from plato.data.tokenizer import Tokenizer\n",
    "\n",
    "\n",
    "VOCAB_PATH='model/Bert/vocab.txt'\n",
    "tokenizer = Tokenizer(vocab_path=VOCAB_PATH)\n",
    "    \n",
    "src = [tokenizer.tokenize(s) for s in src.split(\" __eou__ \")]\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily，valid，第75行\n",
    "\n",
    "line = \"Oh , well . It was fun to be the winner . But ... it's too big . I must be an extra small in the States . __eou__ So what about the tennis racket ? __eou__ Look ! It's amazing . I can't wait to try it out !\tHow much did that end up costing you ?\"\n",
    "src, tgt = line.strip(\"\\n\").split(\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh , well . It was fun to be the winner . But ... it's too big . I must be an extra small in the States . __eou__ So what about the tennis racket ? __eou__ Look ! It's amazing . I can't wait to try it out !\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much did that end up costing you ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['oh',\n",
       "  ',',\n",
       "  'well',\n",
       "  '.',\n",
       "  'it',\n",
       "  'was',\n",
       "  'fun',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'winner',\n",
       "  '.',\n",
       "  'but',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'too',\n",
       "  'big',\n",
       "  '.',\n",
       "  'i',\n",
       "  'must',\n",
       "  'be',\n",
       "  'an',\n",
       "  'extra',\n",
       "  'small',\n",
       "  'in',\n",
       "  'the',\n",
       "  'states',\n",
       "  '.'],\n",
       " ['so', 'what', 'about', 'the', 'tennis', 'rack', '##et', '?'],\n",
       " ['look',\n",
       "  '!',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'amazing',\n",
       "  '.',\n",
       "  'i',\n",
       "  'can',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'wait',\n",
       "  'to',\n",
       "  'try',\n",
       "  'it',\n",
       "  'out',\n",
       "  '!']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "src = [tokenizer.tokenize(s) for s in src.split(\" __eou__ \")]\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much did that end up costing you ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2129, 2172, 2106, 2008, 2203, 2039, 22173, 2017, 1029]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src, tgt = line.strip(\"\\n\").split(\"\\t\")\n",
    "print(tgt)\n",
    "tgt = tokenizer.tokenize(tgt)\n",
    "tokens = tokenizer.convert_tokens_to_ids(tgt)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
